#!/usr/bin/python3
# -*- coding: utf-8 -*-

from __future__ import unicode_literals, print_function
import argparse
import os.path
import numpy as np
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as pl
import matplotlib.gridspec

from photon_tools.utils import in_intervals
from photon_tools.io import read_photons
from photon_tools.bin_photons import bin_photons
from photon_tools.fcs_models import *
from scipy.stats import linregress
import squmfit
from config_file import Config

parser = argparse.ArgumentParser()
parser.add_argument('file', nargs='+', type=argparse.FileType('r'), help='Timestamp file')
parser.add_argument('-O', '--offset', action='store_true', help='Fit an offset')
parser.add_argument('-t', '--triplet', help='Fit a triplet correction ("fit" or a timescale in microseconds)')
parser.add_argument('-T', '--taus', nargs='+', default=[], action='append',
                    help='Initial diffusion lifetimes (in microseconds). The number of components in the model is derived from the number of arguments given here.')
parser.add_argument('-A', '--aspect', type=float, default=10, help='Fix aspect ratio')
args = parser.parse_args()

large_bin = 1 # second
small_bin = 2e-3 # second
small_length = 1 # second
taus = args.taus
if len(taus) == 0:
    taus = [100, 5000]

def load_corr(fname):
    try:
        return np.genfromtxt(fname, dtype=float, names='lag,G,var')
    except Exception as e:
        print('Failed to load correlation function %s: %s'% (fname, e))
        return None

def build_model(corr, initial_taus, triplet=False, offset=False, initial_amps=None):
    fit = squmfit.Fit()
    lifetimes = [fit.param('tauD-%d' % i, initial=initial)
                 for i,initial in enumerate(initial_taus)]
    lag = squmfit.Argument('lag')
    model = 0 if not offset else fit.param('offset', 0)
    model += 1
    if initial_amps is None:
        initial_amps = [1. / g[-1]['G'] / len(lifetimes)] * len(lifetimes)
    for comp_idx, (tauD, amp) in enumerate(zip(lifetimes, initial_amps)):
        n = fit.param('N-%d' % (comp_idx), initial=amp)
        model += three_dim_diffusion(lag=lag, tauD=1e-6 * tauD, aspect=args.aspect, n=n, alpha=1)
    if triplet is not None:
        tauF = fit.param('tauF', initial=1) if triplet == 'fit' else float(triplet)
        model *= triplet_correction(lag=lag, tauF=1e-6 * tauF,
                                    tripletFrac=fit.param('F', initial=0))

    fit.add_curve('curve', model, corr['G'], weights=1/np.maximum(1e-5, sqrt(corr['var'])), lag=corr['lag'])
    return fit.fit()

for f in args.file:
    ts = read_photons.open(f.name)

    with Config() as config:
        exclude_info = config.get(f.name, {}).get('exclude', {})
        excludes = exclude_info.get('intervals', [])
        if len(excludes) > 0:
            print('    excludes = ', excludes)
        excludes_ticks = [(e[0] / ts.jiffy, e[1] / ts.jiffy) for e in excludes]
        exclude = lambda d: d[np.logical_not(in_intervals(excludes_ticks, d))]

    fig = pl.figure(figsize=(8.0, 10.5))
    gs = matplotlib.gridspec.GridSpec(5, 3)
    fig.suptitle(f.name)

    small_traj_plt = pl.subplot(gs[1, 0])
    small_traj_plt.set_ylabel('counts')
    small_traj_plt.set_title('counts per %g sec' % small_bin)
    small_traj_plt.locator_params(nbins=3)

    large_traj_plt = pl.subplot(gs[1, 1:2])
    large_traj_plt.set_title('counts per %g sec' % large_bin)
    large_traj_plt.locator_params(nbins=3)
    for start,end in excludes:
        pl.axvspan(start, end, alpha=0.3, color='0.3')

    exclude_thresh = exclude_info.get('threshold')
    if exclude_thresh is not None:
        pl.axhline(exclude_thresh, c='k')

    corr_plt = pl.subplot(gs[2:4, 0:2])
    resid_plt = pl.subplot(gs[4, 0:2])
    corr_plt.set_xscale('log')
    resid_plt.set_xscale('log')

    pch_plt = pl.subplot(gs[1, 2])
    pch_plt.locator_params(nbins=3)
    pch_plt.set_xlabel('photons per %g sec' % small_bin)
    pch_plt.set_ylabel('probability density')
    pch_plt.yaxis.set_label_position('right')

    text = ''
    text += 'jiffy = %g ns\n' % (ts.jiffy / 1e-9)
    text += 'contamination threshold factor = %s\n' % exclude_info.get('threshold-factor')
    for c in ts.valid_channels:
        d = None
        try:
            d = ts.channel(c)
        except Exception as e:
            print('Error reading timestamps for channel %d: %s' % (c, e))
            continue

        N = len(d)
        if N == 0:
            continue
        dur = d[-1] - d[0]
        dur *= ts.jiffy
        bins = bin_photons(d, large_bin / ts.jiffy)
        m, b, r, p, stderr = linregress(bins['start_t'], bins['count'])

        text += '    channel %s: T=%1.1f seconds, N=%1.2e\n' % (c, dur, N)
        text += '        rate = %1.1f Hz, std dev = %1.1f Hz\n' % (N / dur, np.std(bins['count']))
        text += '        dI/dt = %g ± %1.1g Hz / second\n' % (m / ts.jiffy, stderr / ts.jiffy)
        text += '\n'

        large_traj_plt.plot(bins['start_t'] * ts.jiffy, bins['count'])

        middle = (d[-1] - d[0]) // 2 + d[0]
        bins = bin_photons(d, small_bin / ts.jiffy, start_t=middle, end_t=middle + 1/ts.jiffy)
        small_traj_plt.plot(bins['start_t'] * ts.jiffy, bins['count'])

        g = load_corr('%s.acorr-%d' % (f.name, c))
        if g is not None:
            g = g[np.logical_not(np.isnan(g['var']))] # FIXME
            corr_plt.errorbar(g['lag'], g['G'], fmt='+', yerr=np.sqrt(g['var']), label='ch%d' % c,
                              alpha=0.4)
        else:
            print('No autocorrelation for channel %d' % c)

        pch = bin_photons(d, small_bin / ts.jiffy, include_zeros=False)
        upper = np.percentile(pch['count'], 90) # 1e5 * small_bin
        pch_plt.hist(pch['count'], normed=True, range=(0, upper), bins=upper, alpha=0.3)

    large_traj_plt.autoscale(axis='both', tight=True)
    small_traj_plt.autoscale(axis='both', tight=True)

    ((x,y), _) = gs[0,0].get_position(fig).get_points()
    fig.text(x, y, text)

    # Cross-correlation
    g = load_corr('%s.xcorr-0-1' % f.name)
    if g is not None:
        corr_plt.errorbar(g['lag'], g['G'], fmt='+', yerr=np.sqrt(g['var']), label='xcorr', alpha=0.4)
        corr_plt.set_ylim(0.8, 1.2 * g['G'].max())

        # Fit
        g = g[np.logical_not(np.isnan(g['var']))] # FIXME
        g = g[g['lag'] > 1e-6]

        # First fit taus without triplet as it tends to send the fit in the wrong direction
        res = build_model(g, taus, triplet=False, offset=False)

        # then fit with the triplet
        if args.triplet:
            corr_plt.plot(g['lag'], res.curves['curve'].fit, label='fit (no triplet)')
            res = build_model(g,
                              initial_taus=[res.eval(res.fit.param_set.params['tauD-%d' % i])
                                            for i in range(len(taus))],
                              initial_amps=[res.eval(res.fit.param_set.params['N-%d' % i])
                                            for i in range(len(taus))],
                              triplet=True, offset=args.offset)

        # Plot
        corr_plt.plot(g['lag'], res.curves['curve'].fit, label='fit')
        corr_plt.axhline(1, c='k')
        pl.setp(corr_plt.get_xticklabels(), visible=False)
        resid_plt.plot(g['lag'], res.curves['curve'].residuals, '+')
        resid_plt.axhline(0, c='k')
        resid_plt.set_xlabel(r'$\tau$ (microseconds)')
        corr_plt.set_ylabel(r'$G(\tau)$')

        ((x,y), _) = gs[3,2].get_position(fig).get_points()
        text = 'reduced $\\chi^2$ = %f\n' % res.curves['curve'].reduced_chi_sqr
        text += '\n'.join('%15s = %4.2f ± %4.2f' % (param.name, res.eval(param), -1 if res.stderr is None else res.stderr[param.name])
                          for param in sorted(res.fit.param_set.params.values(),
                                              key=lambda x: x.name))
        fig.text(x, y, text, fontsize='small')
    else:
        print('failed to compute cross-correlation')

    # Correlation plot legend
    handles, labels = corr_plt.get_legend_handles_labels()
    fig.legend(handles=handles, labels=labels,
                loc='upper left',
                bbox_to_anchor= gs[2,2].get_position(fig),
                bbox_transform=fig.transFigure,
                mode='expand', fontsize='small', ncol=1, frameon=False)

    pl.savefig(f.name+'.summary.svg')

    print()

